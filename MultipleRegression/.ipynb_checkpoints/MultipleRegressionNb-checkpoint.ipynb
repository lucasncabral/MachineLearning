{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Universidade Federal de Campina Grande\n",
    "#### Departamento de Sistemas e Computação\n",
    "#### Lucas Nascimento Cabral\n",
    "\n",
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o intuito de desenvolver o que foi requisitado pelo professor, foi utilizado a versão vetorizada implementada no notebook disponibilizado pelo professor para a regressão simples. O código extraído segue logo abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at w0 = [0.], w1 = [0.], error = [[2946.63449705]]\n",
      "Running...\n",
      "MSE na iteração 0 é de [[1192.54554729]]\n",
      "MSE na iteração 1000 é de [[72.17883367]]\n",
      "MSE na iteração 2000 é de [[53.76174367]]\n",
      "MSE na iteração 3000 é de [[43.35384055]]\n",
      "MSE na iteração 4000 é de [[37.4721053]]\n",
      "MSE na iteração 5000 é de [[34.14820718]]\n",
      "MSE na iteração 6000 é de [[32.26979916]]\n",
      "MSE na iteração 7000 é de [[31.20826943]]\n",
      "MSE na iteração 8000 é de [[30.60837559]]\n",
      "MSE na iteração 9000 é de [[30.26936238]]\n",
      "MSE na iteração 10000 é de [[30.07777855]]\n",
      "MSE na iteração 11000 é de [[29.9695103]]\n",
      "MSE na iteração 12000 é de [[29.90832554]]\n",
      "MSE na iteração 13000 é de [[29.87374868]]\n",
      "MSE na iteração 14000 é de [[29.85420853]]\n",
      "MSE na iteração 15000 é de [[29.84316597]]\n",
      "MSE na iteração 16000 é de [[29.83692557]]\n",
      "Gradiente descendente convergiu com w0 = [-39.09650898], w1 = [5.57866311], error = [[29.83465362]]\n",
      "Versão vetorizada rodou em: 389.94908332824707 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "def compute_mse_vectorized(w,X,Y):\n",
    "    res = Y - np.dot(X,w)\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(Y))\n",
    "\n",
    "def step_gradient_vectorized(w_current,X,Y,learningRate):\n",
    "    res = Y - np.dot(X,w_current)\n",
    "    b_gradient = np.sum(res)\n",
    "    X = X[:,1][:,np.newaxis]\n",
    "    m_gradient = np.sum(np.multiply(res,X))\n",
    "    new_w = np.array([(w_current[0] + (2 * learningRate * b_gradient)),\n",
    "             (w_current[1] + (2 * learningRate * m_gradient))])\n",
    "    return [new_w,b_gradient,m_gradient]\n",
    "\n",
    "def gradient_descent_runner_vectorized(starting_w, X,Y, learning_rate, epsilon):\n",
    "    w = starting_w\n",
    "    grad = np.array([np.inf,np.inf])\n",
    "    i = 0\n",
    "    while (np.linalg.norm(grad)>=epsilon):\n",
    "        w,b_gradient,m_gradient = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "        grad = np.array([b_gradient,m_gradient])\n",
    "        #print(np.linalg.norm(grad))\n",
    "        if i % 1000 == 0:\n",
    "            print(\"MSE na iteração {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))\n",
    "        i+= 1\n",
    "    return w\n",
    "\n",
    "points = np.genfromtxt(\"income.csv\", delimiter=\",\")\n",
    "points = np.c_[np.ones(len(points)),points]\n",
    "X = points[:,[0,1]]\n",
    "Y = points[:,2][:,np.newaxis]\n",
    "init_w = np.zeros((2,1))\n",
    "learning_rate = 0.0001\n",
    "#num_iterations = 10000\n",
    "epsilon = 0.5\n",
    "print(\"Starting gradient descent at w0 = {0}, w1 = {1}, error = {2}\".format(init_w[0], init_w[1], compute_mse_vectorized(init_w, X,Y)))\n",
    "print(\"Running...\")\n",
    "tic = time.time()\n",
    "w = gradient_descent_runner_vectorized(init_w, X,Y, learning_rate, epsilon)\n",
    "toc = time.time()\n",
    "print(\"Gradiente descendente convergiu com w0 = {0}, w1 = {1}, error = {2}\".format(w[0], w[1], compute_mse_vectorized(w,X,Y)))\n",
    "print(\"Versão vetorizada rodou em: \" + str(1000*(toc-tic)) + \" ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rode o algoritmo [nesses dados](https://canvas.instructure.com/courses/1389733/files/68372968), onde as linhas representam as notas de alunos de computação de alunos da UFCG em algumas disciplinas do primeiro período. A última coluna é a variável alvo representando o CRA final depois de concluir o curso. As outras colunas são algumas disciplinas do primeiro período. O pressuposto aqui é que as notas em disciplinas no primeiro período ajudam a explicar o CRA final dos alunos de computação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram necessárias as seguintes modificações no algoritmo para aceitarmos a quantidade de atributos dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient_vectorized(w_current,X,Y,learningRate):\n",
    "    res = Y - np.dot(X,w_current)\n",
    "    gradient = np.multiply(res,X)\n",
    "    gradient = np.sum(gradient,axis=0)\n",
    "    gradient = gradient[:,np.newaxis]\n",
    "    new_w = w_current + 2 * learningRate * gradient\n",
    "    return [new_w,gradient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_runner_vectorized(starting_w, X,Y, learning_rate, epsilon):\n",
    "    w = starting_w\n",
    "    grad = np.array([np.inf])\n",
    "    i = 0\n",
    "    while (np.linalg.norm(grad)>=epsilon):\n",
    "        w,grad = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "        if(i % 1000 == 0):\n",
    "            print(\"MSE na iteração {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))\n",
    "        i+= 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após alguns testes, o valor de learning_rate e epsilon foram ajustados para atender as necessidades dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at w0 = [0.], w1 = [0.], w2 = [0.], w3 = [0.], w4 = [0.], w5 = [0.] and error = [[54.47995386]]\n",
      "Running...\n",
      "MSE na iteração 0 é de [[15.39415211]]\n",
      "MSE na iteração 1000 é de [[0.43036269]]\n",
      "MSE na iteração 2000 é de [[0.42891282]]\n",
      "MSE na iteração 3000 é de [[0.42766679]]\n",
      "MSE na iteração 4000 é de [[0.42650933]]\n",
      "MSE na iteração 5000 é de [[0.42543391]]\n",
      "MSE na iteração 6000 é de [[0.42443472]]\n",
      "MSE na iteração 7000 é de [[0.42350635]]\n",
      "MSE na iteração 8000 é de [[0.42264379]]\n",
      "MSE na iteração 9000 é de [[0.42184238]]\n",
      "MSE na iteração 10000 é de [[0.42109776]]\n",
      "MSE na iteração 11000 é de [[0.42040593]]\n",
      "MSE na iteração 12000 é de [[0.41976314]]\n",
      "MSE na iteração 13000 é de [[0.41916591]]\n",
      "MSE na iteração 14000 é de [[0.41861102]]\n",
      "MSE na iteração 15000 é de [[0.41809545]]\n",
      "MSE na iteração 16000 é de [[0.41761644]]\n",
      "MSE na iteração 17000 é de [[0.41717137]]\n",
      "MSE na iteração 18000 é de [[0.41675786]]\n",
      "MSE na iteração 19000 é de [[0.41637365]]\n",
      "MSE na iteração 20000 é de [[0.41601668]]\n",
      "MSE na iteração 21000 é de [[0.41568501]]\n",
      "MSE na iteração 22000 é de [[0.41537685]]\n",
      "MSE na iteração 23000 é de [[0.41509054]]\n",
      "MSE na iteração 24000 é de [[0.41482452]]\n",
      "MSE na iteração 25000 é de [[0.41457735]]\n",
      "MSE na iteração 26000 é de [[0.41434771]]\n",
      "MSE na iteração 27000 é de [[0.41413434]]\n",
      "MSE na iteração 28000 é de [[0.4139361]]\n",
      "MSE na iteração 29000 é de [[0.41375191]]\n",
      "MSE na iteração 30000 é de [[0.41358078]]\n",
      "MSE na iteração 31000 é de [[0.41342177]]\n",
      "MSE na iteração 32000 é de [[0.41327404]]\n",
      "MSE na iteração 33000 é de [[0.41313678]]\n",
      "MSE na iteração 34000 é de [[0.41300925]]\n",
      "MSE na iteração 35000 é de [[0.41289075]]\n",
      "MSE na iteração 36000 é de [[0.41278066]]\n",
      "MSE na iteração 37000 é de [[0.41267837]]\n",
      "MSE na iteração 38000 é de [[0.41258333]]\n",
      "MSE na iteração 39000 é de [[0.41249503]]\n",
      "MSE na iteração 40000 é de [[0.41241299]]\n",
      "MSE na iteração 41000 é de [[0.41233676]]\n",
      "MSE na iteração 42000 é de [[0.41226594]]\n",
      "MSE na iteração 43000 é de [[0.41220013]]\n",
      "MSE na iteração 44000 é de [[0.41213899]]\n",
      "MSE na iteração 45000 é de [[0.41208219]]\n",
      "MSE na iteração 46000 é de [[0.41202941]]\n",
      "MSE na iteração 47000 é de [[0.41198037]]\n",
      "MSE na iteração 48000 é de [[0.41193481]]\n",
      "MSE na iteração 49000 é de [[0.41189247]]\n",
      "MSE na iteração 50000 é de [[0.41185314]]\n",
      "MSE na iteração 51000 é de [[0.4118166]]\n",
      "MSE na iteração 52000 é de [[0.41178264]]\n",
      "MSE na iteração 53000 é de [[0.4117511]]\n",
      "MSE na iteração 54000 é de [[0.41172179]]\n",
      "MSE na iteração 55000 é de [[0.41169455]]\n",
      "MSE na iteração 56000 é de [[0.41166925]]\n",
      "MSE na iteração 57000 é de [[0.41164574]]\n",
      "MSE na iteração 58000 é de [[0.4116239]]\n",
      "MSE na iteração 59000 é de [[0.4116036]]\n",
      "MSE na iteração 60000 é de [[0.41158475]]\n",
      "MSE na iteração 61000 é de [[0.41156723]]\n",
      "MSE na iteração 62000 é de [[0.41155095]]\n",
      "MSE na iteração 63000 é de [[0.41153583]]\n",
      "MSE na iteração 64000 é de [[0.41152178]]\n",
      "MSE na iteração 65000 é de [[0.41150872]]\n",
      "MSE na iteração 66000 é de [[0.41149659]]\n",
      "MSE na iteração 67000 é de [[0.41148532]]\n",
      "MSE na iteração 68000 é de [[0.41147485]]\n",
      "MSE na iteração 69000 é de [[0.41146512]]\n",
      "MSE na iteração 70000 é de [[0.41145608]]\n",
      "MSE na iteração 71000 é de [[0.41144768]]\n",
      "MSE na iteração 72000 é de [[0.41143988]]\n",
      "MSE na iteração 73000 é de [[0.41143263]]\n",
      "MSE na iteração 74000 é de [[0.41142589]]\n",
      "MSE na iteração 75000 é de [[0.41141963]]\n",
      "MSE na iteração 76000 é de [[0.41141382]]\n",
      "MSE na iteração 77000 é de [[0.41140841]]\n",
      "MSE na iteração 78000 é de [[0.41140339]]\n",
      "MSE na iteração 79000 é de [[0.41139873]]\n",
      "MSE na iteração 80000 é de [[0.41139439]]\n",
      "MSE na iteração 81000 é de [[0.41139037]]\n",
      "MSE na iteração 82000 é de [[0.41138663]]\n",
      "MSE na iteração 83000 é de [[0.41138315]]\n",
      "MSE na iteração 84000 é de [[0.41137992]]\n",
      "MSE na iteração 85000 é de [[0.41137692]]\n",
      "MSE na iteração 86000 é de [[0.41137413]]\n",
      "MSE na iteração 87000 é de [[0.41137154]]\n",
      "MSE na iteração 88000 é de [[0.41136914]]\n",
      "MSE na iteração 89000 é de [[0.4113669]]\n",
      "MSE na iteração 90000 é de [[0.41136482]]\n",
      "MSE na iteração 91000 é de [[0.41136289]]\n",
      "MSE na iteração 92000 é de [[0.4113611]]\n",
      "MSE na iteração 93000 é de [[0.41135943]]\n",
      "MSE na iteração 94000 é de [[0.41135788]]\n",
      "MSE na iteração 95000 é de [[0.41135644]]\n",
      "MSE na iteração 96000 é de [[0.41135511]]\n",
      "MSE na iteração 97000 é de [[0.41135387]]\n",
      "MSE na iteração 98000 é de [[0.41135271]]\n",
      "MSE na iteração 99000 é de [[0.41135164]]\n",
      "MSE na iteração 100000 é de [[0.41135064]]\n",
      "MSE na iteração 101000 é de [[0.41134972]]\n",
      "MSE na iteração 102000 é de [[0.41134886]]\n",
      "MSE na iteração 103000 é de [[0.41134806]]\n",
      "MSE na iteração 104000 é de [[0.41134732]]\n",
      "MSE na iteração 105000 é de [[0.41134663]]\n",
      "MSE na iteração 106000 é de [[0.41134599]]\n",
      "MSE na iteração 107000 é de [[0.41134539]]\n",
      "MSE na iteração 108000 é de [[0.41134484]]\n",
      "MSE na iteração 109000 é de [[0.41134433]]\n",
      "MSE na iteração 110000 é de [[0.41134385]]\n",
      "MSE na iteração 111000 é de [[0.4113434]]\n",
      "MSE na iteração 112000 é de [[0.41134299]]\n",
      "MSE na iteração 113000 é de [[0.41134261]]\n",
      "MSE na iteração 114000 é de [[0.41134225]]\n",
      "MSE na iteração 115000 é de [[0.41134192]]\n",
      "MSE na iteração 116000 é de [[0.41134162]]\n",
      "MSE na iteração 117000 é de [[0.41134133]]\n",
      "MSE na iteração 118000 é de [[0.41134107]]\n",
      "MSE na iteração 119000 é de [[0.41134082]]\n",
      "MSE na iteração 120000 é de [[0.41134059]]\n",
      "MSE na iteração 121000 é de [[0.41134038]]\n",
      "MSE na iteração 122000 é de [[0.41134018]]\n",
      "MSE na iteração 123000 é de [[0.41134]]\n",
      "MSE na iteração 124000 é de [[0.41133983]]\n",
      "MSE na iteração 125000 é de [[0.41133967]]\n",
      "MSE na iteração 126000 é de [[0.41133952]]\n",
      "Gradiente descendente convergiu com w0 = 1.7214319757862273, w1 = 0.10333313833600129, w2 = 0.04718170808359163, w3 = 0.16406125198726337, w4 = 0.38200508559551033, w5 = 0.02047849242976369, error = 0.41133944383813986\n",
      "Versão vetorizada rodou em: 3722.9738235473633 ms\n"
     ]
    }
   ],
   "source": [
    "points = np.genfromtxt(\"sample_treino.csv\", delimiter=\",\")\n",
    "points = np.c_[np.ones(len(points)),points]\n",
    "X = points[:,0:-1]\n",
    "Y = points[:,-1][:,np.newaxis]\n",
    "\n",
    "init_w = np.zeros((len(X[0]),1))\n",
    "learning_rate = 0.00003\n",
    "epsilon = 0.01\n",
    "print(\"Starting gradient descent at w0 = {0}, w1 = {1}, w2 = {2}, w3 = {3}, w4 = {4}, w5 = {5} and error = {6}\".format(init_w[0], init_w[1], init_w[2], init_w[3], init_w[4], init_w[5], compute_mse_vectorized(init_w, X,Y)))\n",
    "print(\"Running...\")\n",
    "tic = time.time()\n",
    "w = gradient_descent_runner_vectorized(init_w, X,Y, learning_rate, epsilon)\n",
    "toc = time.time()\n",
    "print(\"Gradiente descendente convergiu com w0 = {0}, w1 = {1}, w2 = {2}, w3 = {3}, w4 = {4}, w5 = {5}, error = {6}\".format(w[0][0], w[1][0], w[2][0], w[3][0], w[4][0], w[5][0], compute_mse_vectorized(w,X,Y)[0][0]))\n",
    "print(\"Versão vetorizada rodou em: \" + str(1000*(toc-tic)) + \" ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare o valor dos coeficientes estimados pelo seu algoritmo com o valor dos coeficientes da regressão linear do scikit learn para testar se o seu algoritmo está funcionando corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.10304143 0.0464367  0.16409834 0.38117843 0.02027816]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linearR = LinearRegression()\n",
    "linearR.fit(X,Y)\n",
    "print(linearR.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que com exceção do valor para o coeficiente w0, todos os outros coeficientes obtiveram valores muito próximos.\n",
    "    \n",
    "| coeficiente | gradiente descendente | regressão linear |\n",
    "|-------------|-----------------------|------------------|\n",
    "|     w0      |        1.72143        |       0.         |\n",
    "|     w1      |        0.10333        |       0.10304    |\n",
    "|     w2      |        0.04718        |       0.04643    |\n",
    "|     w3      |        0.16406        |       0.16409    |\n",
    "|     w4      |        0.38200        |       0.38117    |\n",
    "|     w5      |        0.02047        |       0.02027    |\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
